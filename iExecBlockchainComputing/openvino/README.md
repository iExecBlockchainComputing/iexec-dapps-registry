# iexec-openvino

OpenVINO toolkit (Open Visual Inference and Neural network Optimization) is a free toolkit facilitating the optimization of a deep learning model from a framework and deployment using an inference engine onto Intel hardware.[2]
The toolkit has two versions: OpenVINO toolkit, which is supported by open source community and Intel Distribution of OpenVINO toolkit, which is supported by Intel. OpenVINO was developed by Intel. The toolkit is cross-platform and free for use under Apache License version 2.0[3]. The toolkit enables a write-once, deploy-anywhere approach to deep learning deployments on Intel platforms, including CPU, integrated GPU, Intel Movidius VPU, and FPGAs.

## Prerequisites

 * iExec installation
 * good iExec infrastructure understanding

## Build

```
.build
```

## Run the app locally

Test the app locally

```
./run
```

## App run script

### **run**

```
./iexec-run
```
